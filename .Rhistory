post.test <- predict(model.log1, data.test.std, type="response") # post probs for test data
# Oversampling adjustment for calculating number of mailings for test set
n.mail.valid <- which.max(profit.log1)
tr.rate <- .1 # typical response rate is .1
vr.rate <- .5 # whereas validation response rate is .5
adj.test.1 <- (n.mail.valid/n.valid.c)/(vr.rate/tr.rate) # adjustment for mail yes
adj.test.0 <- ((n.valid.c-n.mail.valid)/n.valid.c)/((1-vr.rate)/(1-tr.rate)) # adjustment for mail no
adj.test <- adj.test.1/(adj.test.1+adj.test.0) # scale into a proportion
n.mail.test <- round(n.test*adj.test, 0) # calculate number of mailings for test set
cutoff.test <- sort(post.test, decreasing=T)[n.mail.test+1] # set cutoff based on n.mail.test
chat.test <- ifelse(post.test>cutoff.test, 1, 0) # mail to everyone above the cutoff
table(chat.test)
#    0    1
# 1676  331
# based on this model we'll mail to the 331 highest posterior probabilities
# See below for saving chat.test into a file for submission
##### PREDICTION MODELING ######
# Least squares regression
model.ls1 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls1 <- predict(model.ls1, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls1)^2) # mean prediction error
# 1.867523
sd((y.valid - pred.valid.ls1)^2)/sqrt(n.valid.y) # std error
# 0.1696615
# drop wrat for illustrative purposes
model.ls2 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls2 <- predict(model.ls2, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls2)^2) # mean prediction error
# 1.867433
sd((y.valid - pred.valid.ls2)^2)/sqrt(n.valid.y) # std error
# 0.1696498
# Results
# select model.ls2 since it has minimum mean prediction error in the validation sample
yhat.test <- predict(model.ls2, newdata = data.test.std) # test predictions
# FINAL RESULTS
# Save final results for both classification and regression
length(chat.test) # check length = 2007
length(yhat.test) # check length = 2007
chat.test[1:10] # check this consists of 0s and 1s
yhat.test[1:10] # check this consists of plausible predictions of damt
ip <- data.frame(chat=chat.test, yhat=yhat.test) # data frame with two variables: chat and yhat
write.csv(ip, file="GHK.csv", row.names=FALSE) # use your initials for the file name
cv.out = cv.glmnet(x.train, y.train, alpha = 1)
library(glmnet)
cv.out = cv.glmnet(x.train, y.train, alpha = 1)
data.train <- charity.t[charity$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
library(glmnet)
cv.out = cv.glmnet(x.train, y.train, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
library(glmnet)
cv.out = cv.glmnet(x.train, c.train, alpha = 1)
library(glmnet)
x = model.matrix(y ~ ., data = data.all)[,-1]
library(glmnet)
x = model.matrix(y ~ ., data = data.train)[,-1]
data.train
x = model.matrix(damt ~ ., data = data.train)[,-1]
x.train = x[-data.test,]
cv.out = cv.glmnet(x.train, c.train, alpha = 1)
cv.out = cv.glmnet(x.train, y.train, alpha = 1)
x
library(glmnet)
x = model.matrix(damt ~ ., data = data.train)[,-1]
x.train <- data.train[,2:21]
c.train <- data.train[,22]
cv.out = cv.glmnet(x.train, y.train, alpha = 1)
cv.out = cv.glmnet(x.train, c.train, alpha = 1)
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.train,y.train,alpha=1,lambda=lasso.lambda)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=x.test)
x.test <- data.test[,2:21]
lasso.test=predict(lasso.train,newx=x.test)
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=lasso)
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
lasso.test = lasso[test,]
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
lasso.test = lasso[x.test,]
lasso.test = lasso[as.matrix(x.test),]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=lasso)
lasso.test=predict(lasso.train,newx=lasso.test)
lasso.test=predict(lasso.train,newx=as.matrix(lasso.test))
lasso.test=predict(lasso.train,newx=lasso.test)
#############################################
# PREDICT 422 Practical Machine Learning    #
# Laura Stotts Gorans, Phil Harm, Tim Kiely #
#############################################
#Load Data
path = 'E:\\Northwestern\\Classes\\pred422\\final'
fname = 'charity.csv'
charity <- read.csv(file=file.path(path,fname)) # load the "charity.csv" file
##########################################
#REQUIREMENT 1 - Exploratory Data Analyis#
##########################################
#Set-up Transformations
charity.t <- charity
charity.t$avhv <- log(charity.t$avhv)
#Partition Data
data.train <- charity.t[charity$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
data.valid <- charity.t[charity$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999
data.test <- charity.t[charity$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]
x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1
x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1
x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)
##########################################
#REQUIREMENT 2 - CLASSIFICATION MODELING #
##########################################
#~~~~~~~~~~~~~~
# LINEAR DICSRIMINANT ANALYSIS
#~~~~~~~~~~~~~~
library(MASS)
model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c) # include additional terms on the fly using I()
post.valid.lda1 <- predict(model.lda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs
#calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.lda1 <- cumsum(14.5*c.valid[order(post.valid.lda1, decreasing=T)]-2)
plot(profit.lda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.lda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.lda1)) # report number of mailings and maximum profit
cutoff.lda1 <- sort(post.valid.lda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.lda1 <- ifelse(post.valid.lda1>cutoff.lda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.lda1, c.valid) # classification table
#~~~~~~~~~~~~~~
# LOGSITIC REGRESSION
#~~~~~~~~~~~~~~
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
# calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.log1)) # report number of mailings and maximum profit
cutoff.log1 <- sort(post.valid.log1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
table(chat.valid.log1, c.valid) # classification table
chat.valid.log1 <- ifelse(post.valid.log1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
# select model.log1 since it has maximum profit in the validation sample
post.test <- predict(model.log1, data.test.std, type="response") # post probs for test data
# Oversampling adjustment for calculating number of mailings for test set
n.mail.valid <- which.max(profit.log1)
library(MASS)
model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c) # include additional terms on the fly using I()
post.valid.lda1 <- predict(model.lda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs
#calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.lda1 <- cumsum(14.5*c.valid[order(post.valid.lda1, decreasing=T)]-2)
plot(profit.lda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.lda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.lda1)) # report number of mailings and maximum profit
cutoff.lda1 <- sort(post.valid.lda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.lda1 <- ifelse(post.valid.lda1>cutoff.lda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.lda1, c.valid) # classification table
#~~~~~~~~~~~~~~
# LOGSITIC REGRESSION
#~~~~~~~~~~~~~~
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
# calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.log1)) # report number of mailings and maximum profit
cutoff.log1 <- sort(post.valid.log1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.log1 <- ifelse(post.valid.log1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.log1, c.valid) # classification table
# select model.log1 since it has maximum profit in the validation sample
post.test <- predict(model.log1, data.test.std, type="response") # post probs for test data
# Oversampling adjustment for calculating number of mailings for test set
n.mail.valid <- which.max(profit.log1)
tr.rate <- .1 # typical response rate is .1
vr.rate <- .5 # whereas validation response rate is .5
adj.test.1 <- (n.mail.valid/n.valid.c)/(vr.rate/tr.rate) # adjustment for mail yes
adj.test.0 <- ((n.valid.c-n.mail.valid)/n.valid.c)/((1-vr.rate)/(1-tr.rate)) # adjustment for mail no
adj.test <- adj.test.1/(adj.test.1+adj.test.0) # scale into a proportion
n.mail.test <- round(n.test*adj.test, 0) # calculate number of mailings for test set
cutoff.test <- sort(post.test, decreasing=T)[n.mail.test+1] # set cutoff based on n.mail.test
chat.test <- ifelse(post.test>cutoff.test, 1, 0) # mail to everyone above the cutoff
table(chat.test)
##########################################
#REQUIREMENT 3 - PREDICTION MODELING     #
##########################################
#~~~~~~~~~~~~~~
# LEAST SQUARES REGRESSION
#~~~~~~~~~~~~~~
model.ls1 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls1 <- predict(model.ls1, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls1)^2) # mean prediction error
sd((y.valid - pred.valid.ls1)^2)/sqrt(n.valid.y) # std error
# drop wrat for illustrative purposes
model.ls2 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls2 <- predict(model.ls2, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls2)^2) # mean prediction error
sd((y.valid - pred.valid.ls2)^2)/sqrt(n.valid.y) # std error
# select model.ls2 since it has minimum mean prediction error in the validation sample
yhat.test <- predict(model.ls2, newdata = data.test.std) # test predictions
#~~~~~~~~~~~~~~
# LASSO
#~~~~~~~~~~~~~
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
lasso.test = lasso[as.matrix(x.test),]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=lasso.test)
lasso.test=predict(lasso.train,newx=x.test)
lasso.test=predict(lasso.train,newx=asmatrix(x.test))
lasso.test=predict(lasso.train,newx=as.matrix(x.test))
#TEST RESULTS
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -y.test)^2)
#TEST RESULTS
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -y.lasso)^2)
y.test <- data.test[-x.test,]
y.test <- data.test[,-x.test]
y.test <- data.test[1,]
mean((lasso.test -y.test)^2)
y = data.train$damt
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
y = data.train$damt
lasso.test = lasso[as.matrix(x.test),]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=as.matrix(x.test))
#TEST RESULTS
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -y)^2)
y.lasso = lasso$damt
data.train
y.lasso = data.train$damt
y.lasso
library(glmnet)
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
y.lasso = data.train$damt
lasso.test = lasso[as.matrix(x.test),]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=as.matrix(x.test))
#TEST RESULTS
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -y)^2)
mean((lasso.test -as.matrix(y))^2)
mean((lasso.test -y.lasso)^2)
summary(lasso.test)
plot(lasso.test)
mean((lasso.test - as.matrix(y.lasso))^2)
y.lasso.test = lasso[as.matrix(data.test)]
y.lasso.test
lasso.test
library(glmnet)
lasso = model.matrix(damt ~ ., data = charity.t)[,-1]
x.lasso.train = x[-data.test,]
x.lasso.train = lasso[-data.test,]
x.lasso.train = lasso[-as.matrix(data.test),]
#############################################
# PREDICT 422 Practical Machine Learning    #
# Laura Stotts Gorans, Phil Harm, Tim Kiely #
#############################################
#Load Data
path = 'E:\\Northwestern\\Classes\\pred422\\final'
fname = 'charity.csv'
charity <- read.csv(file=file.path(path,fname)) # load the "charity.csv" file
##########################################
#REQUIREMENT 1 - Exploratory Data Analyis#
##########################################
#Set-up Transformations
charity.t <- charity
charity.t$avhv <- log(charity.t$avhv)
#Partition Data
data.train <- charity.t[charity$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
data.valid <- charity.t[charity$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999
#Test Predictive Models
data.test <- charity.t[charity$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]
x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1
x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1
x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)
##########################################
#REQUIREMENT 2 - CLASSIFICATION MODELING #
##########################################
#~~~~~~~~~~~~~~
# LINEAR DICSRIMINANT ANALYSIS
#~~~~~~~~~~~~~~
library(MASS)
model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c) # include additional terms on the fly using I()
post.valid.lda1 <- predict(model.lda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs
#calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.lda1 <- cumsum(14.5*c.valid[order(post.valid.lda1, decreasing=T)]-2)
plot(profit.lda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.lda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.lda1)) # report number of mailings and maximum profit
cutoff.lda1 <- sort(post.valid.lda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.lda1 <- ifelse(post.valid.lda1>cutoff.lda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.lda1, c.valid) # classification table
#~~~~~~~~~~~~~~
# LOGSITIC REGRESSION
#~~~~~~~~~~~~~~
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
# calculate ordered profit function using average donation = $14.50 and mailing cost = $2
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.log1)) # report number of mailings and maximum profit
cutoff.log1 <- sort(post.valid.log1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.log1 <- ifelse(post.valid.log1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.log1, c.valid) # classification table
# select model.log1 since it has maximum profit in the validation sample
post.test <- predict(model.log1, data.test.std, type="response") # post probs for test data
# Oversampling adjustment for calculating number of mailings for test set
n.mail.valid <- which.max(profit.log1)
tr.rate <- .1 # typical response rate is .1
vr.rate <- .5 # whereas validation response rate is .5
adj.test.1 <- (n.mail.valid/n.valid.c)/(vr.rate/tr.rate) # adjustment for mail yes
adj.test.0 <- ((n.valid.c-n.mail.valid)/n.valid.c)/((1-vr.rate)/(1-tr.rate)) # adjustment for mail no
adj.test <- adj.test.1/(adj.test.1+adj.test.0) # scale into a proportion
n.mail.test <- round(n.test*adj.test, 0) # calculate number of mailings for test set
cutoff.test <- sort(post.test, decreasing=T)[n.mail.test+1] # set cutoff based on n.mail.test
chat.test <- ifelse(post.test>cutoff.test, 1, 0) # mail to everyone above the cutoff
table(chat.test)
##########################################
#REQUIREMENT 3 - PREDICTION MODELING     #
##########################################
#~~~~~~~~~~~~~~
# LEAST SQUARES REGRESSION
#~~~~~~~~~~~~~~
model.ls1 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls1 <- predict(model.ls1, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls1)^2) # mean prediction error
sd((y.valid - pred.valid.ls1)^2)/sqrt(n.valid.y) # std error
# drop wrat for illustrative purposes
model.ls2 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.y)
pred.valid.ls2 <- predict(model.ls2, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls2)^2) # mean prediction error
sd((y.valid - pred.valid.ls2)^2)/sqrt(n.valid.y) # std error
# select model.ls2 since it has minimum mean prediction error in the validation sample
yhat.test <- predict(model.ls2, newdata = data.test.std) # test predictions
#~~~~~~~~~~~~~~
library(glmnet)
lasso = model.matrix(damt ~ ., data = charity.t)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=data.test)
lasso.test=predict(lasso.train,newx=x.test)
lasso.test=predict(lasso.train,newx=as.matrix(x.test))
#TEST RESULTS
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -data.test$damt)^2)
summary(lasso.test)
plot(lasso.test)
mean((lasso.test -data.test$damt)^2)
mean((lasso.test -as.matrix(data.test$damt))^2)
data.test$damt
data.test
data.test <- charity.t[charity$part=="test",]
data.test
charity.t
lasso = model.matrix(damt ~ ., data = data.train)[,-1]
x.lasso <- lasso[,2:21]
y.lasso <- lasso[,22]
cv.out = cv.glmnet(x.lasso, y.lasso, alpha = 1)
plot(cv.out)
lasso.lambda= cv.out$lambda.1se
lasso.train = glmnet(x.lasso, y.lasso,alpha=1,lambda=lasso.lambda)
coef(lasso.train)
lasso.test=predict(lasso.train,newx=as.matrix(x.valid))
lasso.valid=predict(lasso.train,newx=as.matrix(x.valid))
#TEST RESULTS
summary(lasso.valid)
plot(lasso.valid)
mean((lasso.valid -y.valid)^2)
sd((lasso.test -y.valid)^2)/sqrt(n.train.y)
y.valid
length(y.valid)
length(x.valid)
lasso.valid=predict(lasso.train,newx=x.valid)
as.matrix(
lasso.valid=predict(lasso.train,newx=as.matrix(x.valid))
mean((lasso.valid -as.matrix(y.valid))^2)
mean((lasso.valid -y.valid)^2)
length(x.valid)
length(y.valid)
mean((lasso.valid -c.valid)^2)
sd((lasso.test -n.valid.c)^2)/sqrt(n.train.y)
cv.out = cv.glmnet(x.train, y.train, alpha = 0)
cv.out = cv.glmnet(x.train, c.train, alpha = 0)
